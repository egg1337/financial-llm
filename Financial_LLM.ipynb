{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hyqquJTM0LA"
   },
   "source": [
    "#Financial LLM Research - Complete Pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IsIvrAXM0LB"
   },
   "source": [
    "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R01Ee0s5M0LC",
    "outputId": "08100cd2-d311-4f0f-fe0c-d7d108133cb1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 84.1/84.1 kB 5.4 MB/s eta 0:00:00\n",
      "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "pip install -q transformers>=4.36.0 datasets>=2.15.0 accelerate>=0.25.0\n",
    "pip install -q peft>=0.7.0 bitsandbytes>=0.41.0 sentencepiece protobuf\n",
    "pip install -q tqdm pandas numpy scikit-learn\n",
    "pip install -q rouge-score evaluate\n",
    "\n",
    "echo \"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9iAnilhWM0LC",
    "outputId": "b39ed16b-e6ea-4577-d1d0-acb1bf08fff6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PyTorch version: 2.9.0+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n",
      "GPU: Tesla T4\n",
      "GPU Memory: 15.64 GB\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA –Ω–µ–¥–æ—Å—Ç—É–µ–Ω\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdon2gIBM0LD"
   },
   "source": [
    "#–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "–°–æ–∑–¥–∞–¥–∏–º —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –∏ –æ—Ç–≤–µ—Ç–∞–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0X6EIPTYM0LD",
    "outputId": "cd5f2146-c610-4937-ae7f-506456677f71"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–ü–∞–ø–∫–∏ —Å–æ–∑–¥–∞–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "#–ü–∞–ø–∫–∏\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "Path(\"outputs\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"–ü–∞–ø–∫–∏ —Å–æ–∑–¥–∞–Ω—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oSI-0YNM0LD",
    "outputId": "ee737ee9-effb-44ae-b3f6-b3c5c98978dc"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–°–æ–∑–¥–∞—ë–º —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç...\n",
      "–°–æ–∑–¥–∞–Ω–æ 506 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "\n",
      "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:\n",
      "category\n",
      "calculation           333\n",
      "ratio_analysis        167\n",
      "metric_extraction       1\n",
      "metric_analysis         1\n",
      "esg_risk                1\n",
      "credit_risk             1\n",
      "market_analysis         1\n",
      "statement_analysis      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "def create_financial_dataset():\n",
    "    \"\"\"–°–æ–∑–¥–∞—ë—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç\"\"\"\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
    "    metric_examples = [\n",
    "        {\n",
    "            \"instruction\": \"–ò–∑–≤–ª–µ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞: –°–±–µ—Ä–±–∞–Ω–∫ –æ—Ç—á–∏—Ç–∞–ª—Å—è –æ —á–∏—Å—Ç–æ–π –ø—Ä–∏–±—ã–ª–∏ –ø–æ –ú–°–§–û –∑–∞ 2023 –≥–æ–¥ –≤ —Ä–∞–∑–º–µ—Ä–µ 1,5 —Ç—Ä–ª–Ω —Ä—É–±–ª–µ–π, —á—Ç–æ –Ω–∞ 23% –≤—ã—à–µ –ø—Ä–æ—à–ª–æ–≥–æ–¥–Ω–µ–≥–æ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è. ROE —Å–æ—Å—Ç–∞–≤–∏–ª 24,3%, –∞ —Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –∞–∫—Ç–∏–≤–æ–≤ - 3,8%.\",\n",
    "            \"output\": \"–ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –°–±–µ—Ä–±–∞–Ω–∫–∞ –∑–∞ 2023 –≥–æ–¥:\\n- –ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å (–ú–°–§–û): 1,5 —Ç—Ä–ª–Ω —Ä—É–±–ª–µ–π\\n- –†–æ—Å—Ç –ø—Ä–∏–±—ã–ª–∏: +23% –≥/–≥\\n- ROE (—Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–ø–∏—Ç–∞–ª–∞): 24,3%\\n- ROA (—Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –∞–∫—Ç–∏–≤–æ–≤): 3,8%\",\n",
    "            \"category\": \"metric_extraction\"\n",
    "        },\n",
    "        {\n",
    "            \"instruction\": \"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏: –í—ã—Ä—É—á–∫–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –Ø–Ω–¥–µ–∫—Å –≤—ã—Ä–æ—Å–ª–∞ –¥–æ 365 –º–ª—Ä–¥ —Ä—É–±–ª–µ–π (+32% –≥/–≥), EBITDA —Å–æ—Å—Ç–∞–≤–∏–ª–∞ 89 –º–ª—Ä–¥ —Ä—É–±–ª–µ–π —Å –º–∞—Ä–∂–æ–π 24,4%. –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã —É–≤–µ–ª–∏—á–∏–ª–∏—Å—å –Ω–∞ 28%.\",\n",
    "            \"output\": \"–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –Ø–Ω–¥–µ–∫—Å:\\n\\n–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã:\\n- –í—ã—Ä—É—á–∫–∞: 365 –º–ª—Ä–¥ —Ä—É–± (+32% –≥/–≥) - —Å–∏–ª—å–Ω—ã–π —Ä–æ—Å—Ç\\n- EBITDA: 89 –º–ª—Ä–¥ —Ä—É–±, –º–∞—Ä–∂–∞ 24,4% - –≤—ã—Å–æ–∫–∞—è –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å\\n\\n–¢–æ—á–∫–∏ –≤–Ω–∏–º–∞–Ω–∏—è:\\n- –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã +28% - —Ä–æ—Å—Ç –Ω–∏–∂–µ –≤—ã—Ä—É—á–∫–∏, —á—Ç–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ\\n- –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∏–∑–Ω–µ—Å–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏\",\n",
    "            \"category\": \"metric_analysis\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # 2. –ö—Ä–µ–¥–∏—Ç–Ω—ã–π —Ä–∏—Å–∫\n",
    "    credit_examples = [\n",
    "        {\n",
    "            \"instruction\": \"–û—Ü–µ–Ω–∏ –∫—Ä–µ–¥–∏—Ç–Ω—ã–π —Ä–∏—Å–∫ –∑–∞–µ–º—â–∏–∫–∞: –ò–ü, –≤–æ–∑—Ä–∞—Å—Ç 34 –≥–æ–¥–∞, —Å—Ç–∞–∂ –±–∏–∑–Ω–µ—Å–∞ 5 –ª–µ—Ç, —Å—Ä–µ–¥–Ω–µ–º–µ—Å—è—á–Ω–∞—è –≤—ã—Ä—É—á–∫–∞ 2,8 –º–ª–Ω —Ä—É–±, —á–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å 420 —Ç—ã—Å —Ä—É–±/–º–µ—Å, –¥–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ 15%, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º—ã–π –∫—Ä–µ–¥–∏—Ç 5 –º–ª–Ω —Ä—É–± –Ω–∞ 3 –≥–æ–¥–∞.\",\n",
    "            \"output\": \"–û—Ü–µ–Ω–∫–∞ –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Ä–∏—Å–∫–∞: –ù–ò–ó–ö–ò–ô-–°–†–ï–î–ù–ò–ô\\n\\n–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã:\\n- –°—Ç–∞–±–∏–ª—å–Ω—ã–π –±–∏–∑–Ω–µ—Å (5 –ª–µ—Ç —Ä–∞–±–æ—Ç—ã)\\n- –ó–¥–æ—Ä–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å (~15% –º–∞—Ä–∂–∞)\\n- –ù–∏–∑–∫–∞—è –¥–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ (15%)\\n- –†–∞–∑–º–µ—Ä –∫—Ä–µ–¥–∏—Ç–∞ –ø–æ–∫—Ä—ã–≤–∞–µ—Ç—Å—è 12-–º–µ—Å—è—á–Ω–æ–π –ø—Ä–∏–±—ã–ª—å—é\\n\\n–†–∏—Å–∫–∏:\\n- –ò–ü (–±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ vs –û–û–û)\\n- –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç –æ–¥–Ω–æ–≥–æ –≤–ª–∞–¥–µ–ª—å—Ü–∞\\n\\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –û–î–û–ë–†–ò–¢–¨ —Å —É—Å–ª–æ–≤–∏—è–º–∏:\\n- –°—Ç–∞–≤–∫–∞: 12-14% –≥–æ–¥–æ–≤—ã—Ö\\n- –û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ: –∑–∞–ª–æ–≥ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è/–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏\\n- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: –µ–∂–µ–∫–≤–∞—Ä—Ç–∞–ª—å–Ω–∞—è –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å\",\n",
    "            \"category\": \"credit_risk\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # 3. ESG –∞–Ω–∞–ª–∏–∑\n",
    "    esg_examples = [\n",
    "        {\n",
    "            \"instruction\": \"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π ESG-—Ä–∏—Å–∫–∏ –∫–æ–º–ø–∞–Ω–∏–∏: –ú–µ—Ç–∞–ª–ª—É—Ä–≥–∏—á–µ—Å–∫–∏–π –∫–æ–º–±–∏–Ω–∞—Ç, –≤—ã–±—Ä–æ—Å—ã CO2 –ø—Ä–µ–≤—ã—à–∞—é—Ç –Ω–æ—Ä–º—É –Ω–∞ 15%, 3 —Ç—Ä—É–¥–æ–≤—ã—Ö —Å–ø–æ—Ä–∞ –∑–∞ –≥–æ–¥, –Ω–µ—Ç –ø—É–±–ª–∏—á–Ω–æ–π ESG-–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏, –≤ —Å–æ—Å—Ç–∞–≤–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ 1 –∂–µ–Ω—â–∏–Ω–∞ –∏–∑ 9 —á–ª–µ–Ω–æ–≤.\",\n",
    "            \"output\": \"ESG-—Ä–∏—Å–∫ –ø—Ä–æ—Ñ–∏–ª—å: –í–´–°–û–ö–ò–ô\\n\\nEcological (–≠–∫–æ–ª–æ–≥–∏—è) - –í–´–°–û–ö–ò–ô –†–ò–°–ö:\\n- –ü—Ä–µ–≤—ã—à–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ CO2 –Ω–∞ 15% - —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ —Ä–∏—Å–∫–∏\\n- –í–æ–∑–º–æ–∂–Ω—ã–µ —à—Ç—Ä–∞—Ñ—ã –∏ —É–∂–µ—Å—Ç–æ—á–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π\\n- –†–µ–ø—É—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∏—Å–∫–∏\\n\\nSocial (–°–æ—Ü–∏–∞–ª—å–Ω–∞—è —Å—Ñ–µ—Ä–∞) - –°–†–ï–î–ù–ò–ô –†–ò–°–ö:\\n- 3 —Ç—Ä—É–¥–æ–≤—ã—Ö —Å–ø–æ—Ä–∞ - –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–±–ª–µ–º —Å –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º\\n- –†–∏—Å–∫–∏ –∑–∞–±–∞—Å—Ç–æ–≤–æ–∫ –∏ —Ç–µ–∫—É—á–µ—Å—Ç–∏ –∫–∞–¥—Ä–æ–≤\\n\\nGovernance (–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ) - –°–†–ï–î–ù–ò–ô –†–ò–°–ö:\\n- –ù–∏–∑–∫–æ–µ –≥–µ–Ω–¥–µ—Ä–Ω–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –≤ —Å–æ–≤–µ—Ç–µ (11%)\\n- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ ESG-–æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ - –Ω–∏–∑–∫–∞—è –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å\\n\\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\\n- –¢—Ä–µ–±–æ–≤–∞—Ç—å –ø–ª–∞–Ω —Å–Ω–∏–∂–µ–Ω–∏—è –≤—ã–±—Ä–æ—Å–æ–≤\\n- ESG-—Å–≤—è–∑–∞–Ω–Ω—ã–µ –∫–æ–≤–µ–Ω–∞–Ω—Ç—ã –≤ –∫—Ä–µ–¥–∏—Ç–Ω–æ–º –¥–æ–≥–æ–≤–æ—Ä–µ\\n- –ü—Ä–µ–º–∏—è –∫ —Å—Ç–∞–≤–∫–µ +1-2% –∑–∞ ESG-—Ä–∏—Å–∫–∏\",\n",
    "            \"category\": \"esg_risk\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # 4. –ê–Ω–∞–ª–∏–∑ –±–∞–ª–∞–Ω—Å–∞\n",
    "    statement_examples = [\n",
    "        {\n",
    "            \"instruction\": \"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –±–∞–ª–∞–Ω—Å –∫–æ–º–ø–∞–Ω–∏–∏: –ê–∫—Ç–∏–≤—ã 450 –º–ª–Ω —Ä—É–± (–æ–±–æ—Ä–æ—Ç–Ω—ã–µ 280 –º–ª–Ω), –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ 320 –º–ª–Ω (–∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ 180 –º–ª–Ω), —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª 130 –º–ª–Ω. –í—ã—Ä—É—á–∫–∞ 680 –º–ª–Ω, —á–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å 45 –º–ª–Ω –∑–∞ –≥–æ–¥.\",\n",
    "            \"output\": \"–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –±–∞–ª–∞–Ω—Å–∞:\\n\\n –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:\\n- –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ç–µ–∫—É—â–µ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏: 1.56 (280/180) - –ù–û–†–ú–ê\\n- –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∞–≤—Ç–æ–Ω–æ–º–∏–∏: 0.29 (130/450) - –ù–ò–ñ–ï –ù–û–†–ú–´\\n- Debt-to-Equity: 2.46 (320/130) - –í–´–°–û–ö–ê–Ø –ó–ê–ö–†–ï–î–ò–¢–û–í–ê–ù–ù–û–°–¢–¨\\n- ROE: 34.6% (45/130) - –û–¢–õ–ò–ß–ù–ê–Ø –î–û–•–û–î–ù–û–°–¢–¨\\n- ROA: 10% (45/450) - –•–û–†–û–®–û\\n\\n‚ö†Ô∏è –†–∏—Å–∫–∏:\\n- –í—ã—Å–æ–∫–∞—è –¥–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞\\n- –ù–∏–∑–∫–∞—è –¥–æ–ª—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–∞–ø–∏—Ç–∞–ª–∞\\n\\n‚úÖ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:\\n- –•–æ—Ä–æ—à–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å\\n- –í—ã—Å–æ–∫–∞—è —Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å\\n\\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ë–∏–∑–Ω–µ—Å –ø—Ä–∏–±—ã–ª—å–Ω—ã–π, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç —Ä–µ–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ä–∏—Å–∫–æ–≤.\",\n",
    "            \"category\": \"statement_analysis\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # 5. –ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞\n",
    "    market_examples = [\n",
    "        {\n",
    "            \"instruction\": \"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–µ–Ω–¥: –ö–ª—é—á–µ–≤–∞—è —Å—Ç–∞–≤–∫–∞ –¶–ë –ø–æ–≤—ã—à–µ–Ω–∞ –¥–æ 16%, –∏–Ω—Ñ–ª—è—Ü–∏—è 7,4%, –∏–Ω–¥–µ–∫—Å –ú–æ—Å–ë–∏—Ä–∂–∏ —É–ø–∞–ª –Ω–∞ 3,2% –∑–∞ –Ω–µ–¥–µ–ª—é, —Ä—É–±–ª—å –æ—Å–ª–∞–± –¥–æ 95/$.\",\n",
    "            \"output\": \"–ú–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑:\\n\\n –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã:\\n1. –£–∂–µ—Å—Ç–æ—á–µ–Ω–∏–µ –î–ö–ü (—Å—Ç–∞–≤–∫–∞ 16%) - –¥–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –∫—Ä–µ–¥–∏—Ç–æ–≤–∞–Ω–∏–µ\\n2. –í—ã—Å–æ–∫–∞—è –∏–Ω—Ñ–ª—è—Ü–∏—è (7,4%) - —Ä–∏—Å–∫ –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –ø–æ–≤—ã—à–µ–Ω–∏—è —Å—Ç–∞–≤–∫–∏\\n3. –û—Å–ª–∞–±–ª–µ–Ω–∏–µ —Ä—É–±–ª—è (95/$) - –∏–º–ø–æ—Ä—Ç–æ–∑–∞–≤–∏—Å–∏–º—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–æ–¥ –¥–∞–≤–ª–µ–Ω–∏–µ–º\\n4. –ü–∞–¥–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –ú–æ—Å–ë–∏—Ä–∂–∏ (-3,2%)\\n\\nüíº –í–ª–∏—è–Ω–∏–µ –Ω–∞ —Å–µ–∫—Ç–æ—Ä—ã:\\n- –ë–∞–Ω–∫–∏: +/- (–≤—ã—à–µ –º–∞—Ä–∂–∞, –Ω–æ –Ω–∏–∂–µ —Å–ø—Ä–æ—Å –Ω–∞ –∫—Ä–µ–¥–∏—Ç—ã)\\n- –≠–∫—Å–ø–æ—Ä—Ç–µ—Ä—ã: + (–≤—ã–≥–æ–¥–∞ –æ—Ç —Å–ª–∞–±–æ–≥–æ —Ä—É–±–ª—è)\\n- –†–∏—Ç–µ–π–ª: - (—Å–Ω–∏–∂–µ–Ω–∏–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏)\\n- –°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ: - (–¥–æ—Ä–æ–≥–∞—è –∏–ø–æ—Ç–µ–∫–∞)\\n\\nüìà –ü—Ä–æ–≥–Ω–æ–∑:\\n–í–æ–∑–º–æ–∂–Ω–æ –¥–∞–ª—å–Ω–µ–π—à–µ–µ —É–∂–µ—Å—Ç–æ—á–µ–Ω–∏–µ –ø–æ–ª–∏—Ç–∏–∫–∏ –¶–ë –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏–Ω—Ñ–ª—è—Ü–∏–æ–Ω–Ω–æ–≥–æ –¥–∞–≤–ª–µ–Ω–∏—è.\",\n",
    "            \"category\": \"market_analysis\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã\n",
    "    dataset.extend(metric_examples)\n",
    "    dataset.extend(credit_examples)\n",
    "    dataset.extend(esg_examples)\n",
    "    dataset.extend(statement_examples)\n",
    "    dataset.extend(market_examples)\n",
    "\n",
    "    # 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ (—Ä–∞—Å—á—ë—Ç—ã)\n",
    "    for _ in range(500):\n",
    "        choice = random.choice([\"roe\", \"margin\", \"liquidity\"])\n",
    "\n",
    "        if choice == \"roe\":\n",
    "            profit = random.randint(50, 500)\n",
    "            equity = random.randint(200, 2000)\n",
    "            roe = (profit / equity) * 100\n",
    "\n",
    "            dataset.append({\n",
    "                \"instruction\": f\"–†–∞—Å—Å—á–∏—Ç–∞–π ROE –µ—Å–ª–∏ –ø—Ä–∏–±—ã–ª—å {profit} –º–ª–Ω —Ä—É–±, —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª {equity} –º–ª–Ω —Ä—É–±\",\n",
    "                \"output\": f\"ROE = (–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å / –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª) √ó 100% = ({profit} / {equity}) √ó 100% = {roe:.1f}%\",\n",
    "                \"category\": \"calculation\"\n",
    "            })\n",
    "\n",
    "        elif choice == \"margin\":\n",
    "            revenue = random.randint(500, 5000)\n",
    "            ebitda = random.randint(50, revenue // 2)\n",
    "            margin = (ebitda / revenue) * 100\n",
    "\n",
    "            dataset.append({\n",
    "                \"instruction\": f\"–ö–æ–º–ø–∞–Ω–∏—è –∏–º–µ–µ—Ç –≤—ã—Ä—É—á–∫—É {revenue} –º–ª–Ω —Ä—É–±, EBITDA {ebitda} –º–ª–Ω —Ä—É–±. –†–∞—Å—Å—á–∏—Ç–∞–π EBITDA –º–∞—Ä–∂—É.\",\n",
    "                \"output\": f\"EBITDA –º–∞—Ä–∂–∞ = (EBITDA / –í—ã—Ä—É—á–∫–∞) √ó 100% = ({ebitda} / {revenue}) √ó 100% = {margin:.1f}%\",\n",
    "                \"category\": \"calculation\"\n",
    "            })\n",
    "\n",
    "        else:  # liquidity\n",
    "            current_assets = random.randint(100, 1000)\n",
    "            current_liab = random.randint(50, 800)\n",
    "            ratio = current_assets / current_liab\n",
    "\n",
    "            if ratio >= 2:\n",
    "                assessment = \"–û—Ç–ª–∏—á–Ω–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å, –∫–æ–º–ø–∞–Ω–∏—è –º–æ–∂–µ—Ç –ª–µ–≥–∫–æ –ø–æ–∫—Ä—ã—Ç—å –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞.\"\n",
    "            elif ratio >= 1:\n",
    "                assessment = \"–ù–æ—Ä–º–∞–ª—å–Ω–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –ø–æ–∫—Ä—ã—Ç–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤.\"\n",
    "            else:\n",
    "                assessment = \"–ù–∏–∑–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å, —Ä–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º —Å –ø–æ–≥–∞—à–µ–Ω–∏–µ–º –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤.\"\n",
    "\n",
    "            dataset.append({\n",
    "                \"instruction\": f\"–¢–µ–∫—É—â–∏–µ –∞–∫—Ç–∏–≤—ã {current_assets} –º–ª–Ω, –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ {current_liab} –º–ª–Ω. –û—Ü–µ–Ω–∏ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å.\",\n",
    "                \"output\": f\"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ç–µ–∫—É—â–µ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ = {current_assets}/{current_liab} = {ratio:.2f}. {assessment}\",\n",
    "                \"category\": \"ratio_analysis\"\n",
    "            })\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç\n",
    "print(\"üî® –°–æ–∑–¥–∞—ë–º —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç...\")\n",
    "dataset = create_financial_dataset()\n",
    "print(f\"–°–æ–∑–¥–∞–Ω–æ {len(dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset)\n",
    "print(\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:\")\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qR-9h7tSM0LD",
    "outputId": "b6222cdf-8563-4e09-efbd-4bd8990e6ff0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train: 455 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "Validation: 51 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "\n",
      "–î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ data/\n"
     ]
    }
   ],
   "source": [
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(dataset, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_data)} –ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
    "print(f\"Validation: {len(val_data)} –ø—Ä–∏–º–µ—Ä–æ–≤\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "with open('data/train.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open('data/validation.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(val_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\n–î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHKMcN7mM0LD"
   },
   "source": [
    "#–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEr_FeldM0LE",
    "outputId": "16981432-d79e-4ba3-c066-202935576944"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PsgnBwEDM0LE",
    "outputId": "981d748a-5fb5-48ef-9534-8429e2351b92"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞\n"
     ]
    }
   ],
   "source": [
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
    "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
    "OUTPUT_DIR = \"outputs/financial-mistral-qlora\"\n",
    "\n",
    "# BitsAndBytes config (4-bit quantization)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "print(\"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597,
     "referenced_widgets": [
      "a988c86c088d45b0864693dbc0638ea1",
      "efbecbd4e7874eaa9dbc121eb0ce13f6",
      "8bd5a5ab176940c0bfcf4906abdca299",
      "bcfd2a1585584b79b08fb69db36e93f5",
      "126799d0c71f4276a786bc30ef825ddc",
      "c41353ed56bb4781be41ef30b1bb6589",
      "cda7d4cb3a1442bdbc3600d2b2270409",
      "968157ed511145a19493182ed98b8c04",
      "231d968795a34e2895811ae065072755",
      "032de470d04e407ab4c430d4777931e0",
      "1e48bf76676f4b1eae398fb4f0e14a17",
      "61ac39efcbbe43699a815d1de294a3f9",
      "6a26e25af2304804b14545d8835e7958",
      "b1b3e106ef4043c1870232b46570fe64",
      "2a4cc1f660e94203b7889c321dfe2377",
      "1b38eeed3d3549b78ffdea8ccb584821",
      "f1185b6482c5443982958bed74b6617d",
      "3ae1f445b96b43368103da0bc1126b51",
      "91ec9af3f0f842f8b2f5884f70df9e44",
      "018e1aa6dbd64ddcaefb1011aec0d7ec",
      "f609275fe526404f9d324ae639a4ada8",
      "bc46d2d84a1d49a590497c7e62821ad1",
      "a08dc124029944a2bb579d0687d8bd8f",
      "5dbfdcbf109443e3a42aa9c224f1adda",
      "24c10189047e4f0e965fd7c3ed931a22",
      "223cd0f492474db384b1c253188d586a",
      "809f5280f51c44dbbf935d1a3402ac62",
      "1e8f35300ceb4435864707f71db17ba5",
      "111809ed70544d24bb201112eda70a7e",
      "bfd12c6bdfc6475cb12b03096b8d1bc5",
      "b70e6308ecbe4b019a319c29d47c3584",
      "04407fd704a84b06af0091a0e9fb3ea6",
      "0f72f36ccf7343f685db15c5279aa068",
      "8ca96a0469444efd86fdb4e2c44c1ff8",
      "ec947b33f61e41e9954244cad636704b",
      "4cc7e28b54984bfb8b5c0756a1ec0052",
      "e98a5f9c68fa4c7bb0db7939e76996ca",
      "32ee8ef467754bb686032c696305be68",
      "85427f742d6a44988fb93c8b5f804bd9",
      "b6f12afb206846a6aa2f2d59c571422e",
      "a8f0a3fb4efa41aaa3f7241da3b28d34",
      "4ae5e312e56e4f958937a6ddb1108316",
      "86ccd70341014c3eaebf5787602c0ed3",
      "5a1394e5dd904b60929146ffbea7400f",
      "a0af73b060e441e297479bfa9c625576",
      "621099fd88ca46adb68cff1cfba93c5b",
      "b84773d2ed124c5984ae1d055c9ae433",
      "c2c8c2eeb3bf4eefbcc34c5266bd1f4a",
      "34b4f8ebe1a1491a86f1cf19e5ec1369",
      "9cad66379fbd4b7080b207686f414c75",
      "99b68c72255446098cbcca724fcb8697",
      "8b4b381745dd46cd9141dcae51c3ab14",
      "7d1a9960083746c5b67034836129c2c3",
      "a1da2a4a5c0f437e835748488abe071a",
      "6e6e3d0b3b334253a00e3e0252b8bf22",
      "db6263652cd04d9dbbe4c8b3edd9f29e",
      "448c482ccaa3408c8a6df7602b3a256e",
      "11c613c4ea884b8986533fe3ce166634",
      "59304cb26e5d491e94b013179ead13c8",
      "4e5dcdccf534436d966eaee5a9bb39a3",
      "c900c7cc53cd4adeb0d19dd83af072b2",
      "30d9e0685b86443cbf2bbba87fbabae1",
      "ee6efc89fce0410ab6ce352604034dab",
      "6cfc3198df3a4f1eabbf7bd76af9c675",
      "2fae989bdc304bfe8f1e00d76a20108a",
      "945ef427e12e46f6a020aa482202f698",
      "d668a0a5922344218ff11e5026670450",
      "e38760d18ad848e5a8888aea54edbec9",
      "9a34fdc75f2d4281976d4dc2e8b4fd0c",
      "9f92143f12674a738aad506f7746b59f",
      "1df97928de434f668e0a5dfb47adf6cc",
      "754b2768448140afa24d4a29b89b86cb",
      "cabcc1f863d646acaa5115cb2391d3b9",
      "08d55104b8964cbb9387d1a428393978",
      "09ee8d6244634c52b3c29a985621826d",
      "9b1c0d02993b4e59a373bbd46e02df5f",
      "c542bb1db4dc424f93a07d31abf8975e",
      "3d02819834f0451f82e80df5ddb91f42",
      "857a50f3e70b43b89d19e134012f124b",
      "759b430f21454927a90a433db3c62f83",
      "79fb63f24783459a86acf66a1ecb924c",
      "c4a9fed80b6d4b7280cd3c64b7be6b89",
      "44bf4bb4f3404da59ee8aa13af98120a",
      "51645ca9a9b241b0ae9ee2f4472ea62c",
      "804cc755573d49798960c46a77ed506f",
      "1c8b563d6ac246ec97d3097f0e67027b",
      "1572eb8574ec46b8869e76edd4c13814",
      "ac5644a083c0401db08332928524c84f",
      "63e99acd648b4f9885876d800af61f1c",
      "08faa5a52030429fab0f5442ff258702",
      "5e5de0c79ce74ac182e73563468ea55c",
      "a836f4ae06a14e3b8dc28f46484a5f23",
      "d420b6fc494d4f2caed95e9d730a1d60",
      "e560518074a04489950afb16bbfb0fda",
      "1e59e49aff5f48ddb5959b328c361a0d",
      "0ec5b53501cf4074961b49de61b447a7",
      "fb87bde848bd40408323d3fe15be1b98",
      "fc019d1251754c16be3d6ead905b1441",
      "418d910c5b524d5e9460e5d435a092cb",
      "34caeafc746b4fa584fd84e338c17f30",
      "341609b8e0b944c4ab0f97b74c662b1e",
      "6494debb127844c189940db070436d01",
      "c4e4d03ae4f84d22ba90e3f8fc283da7",
      "bf36c60a3d2045b1b7cd588f8e2cd9a3",
      "b8f06cd090da4d3d99a2743dd416d19d",
      "e84350639d574127a8b68e3f65f148f2",
      "b5c93559461540a18486fc9e2f8b1ce8",
      "048899c4d7114304b4a0bcc161219563",
      "094b8dbd3d2d431dae16d136d68b1b01",
      "4b4e10e841254de0aeeb69dad3d0f268"
     ]
    },
    "id": "jeoOlKyJM0LE",
    "outputId": "0073e3cf-e83e-4415-8cb9-873926f35431"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–ó–∞–≥—Ä—É–∂–∞–µ–º –ë–ê–ó–û–í–£–Æ –º–æ–¥–µ–ª—å Mistral-7B...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a988c86c088d45b0864693dbc0638ea1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61ac39efcbbe43699a815d1de294a3f9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a08dc124029944a2bb579d0687d8bd8f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ca96a0469444efd86fdb4e2c44c1ff8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0af73b060e441e297479bfa9c625576"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db6263652cd04d9dbbe4c8b3edd9f29e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d668a0a5922344218ff11e5026670450"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d02819834f0451f82e80df5ddb91f42"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63e99acd648b4f9885876d800af61f1c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34caeafc746b4fa584fd84e338c17f30"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!\n",
      "–ü–∞–º—è—Ç—å GPU: 4.13 GB\n",
      "Vocab size: 32000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# –ó–ê–ì–†–£–ó–ö–ê –ë–ê–ó–û–í–û–ô –ú–û–î–ï–õ–ò MISTRAL (–ë–ï–ó –ê–î–ê–ü–¢–ï–†–û–í)\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"–ó–∞–≥—Ä—É–∂–∞–µ–º –ë–ê–ó–û–í–£–Æ –º–æ–¥–µ–ª—å Mistral-7B...\")\n",
    "\n",
    "# –ò–°–ü–û–õ–¨–ó–£–ï–ú –ë–ê–ó–û–í–£–Æ –ú–û–î–ï–õ–¨ (–±–µ–∑ LoRA –∞–¥–∞–ø—Ç–µ—Ä–æ–≤!)\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_cache=False,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "print(\"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!\")\n",
    "print(f\"–ü–∞–º—è—Ç—å GPU: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "print(f\"Vocab size: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tv3nCJJUM0LE",
    "outputId": "1dc73807-3fe5-4163-d22a-7821aab7faa9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:\n",
      "–í—Å–µ–≥–æ: 3,919,843,328\n",
      "–û–±—É—á–∞–µ–º—ã—Ö: 167,772,160\n",
      "—Ä–æ—Ü–µ–Ω—Ç: 4.2801%\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
    "trainable_params = 0\n",
    "all_params = 0\n",
    "for _, param in model.named_parameters():\n",
    "    all_params += param.numel()\n",
    "    if param.requires_grad:\n",
    "        trainable_params += param.numel()\n",
    "\n",
    "print(\"\\n–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:\")\n",
    "print(f\"–í—Å–µ–≥–æ: {all_params:,}\")\n",
    "print(f\"–û–±—É—á–∞–µ–º—ã—Ö: {trainable_params:,}\")\n",
    "print(f\"—Ä–æ—Ü–µ–Ω—Ç: {100 * trainable_params / all_params:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "2b1dee852c5b4748842c88af3c6ca0db",
      "cb57a4a244b5414f80362ff6aa97cd4e",
      "d695e2786d3f41619344cce00dda8e84",
      "2ff4338f171147ddb5198da0398ffae8",
      "e5a0b3d35dc04906b8ca67ea27626088",
      "653625f02e3244578f846510fdb797d1",
      "a050376674414c46a0e6905b5c67ef31",
      "a9eed0ad1233421db3009e894fd21138",
      "a347d39c8a744972bf4428c07782d49b",
      "aabc95f3b06c4f779f7bcbc0aa60e85f",
      "54ed3e96ef934145aacf29facd04c360",
      "85e28eea8b874d44ae4651ebae56d7b5",
      "cd70132c9dcd42239842d50dab7182ef",
      "1191c32fe7c749c994b98280708de6e9",
      "69c624d831f3475dafc329e51956327a",
      "0d056c06906f4c37ba9bef00aff0fec7",
      "adbb05bcde854dbebe16a935976a2bd2",
      "a826d10a9800467ab0b42e3be26c577f",
      "47efc209561d492bbbe15995e34a7e61",
      "f42f5d6d4b6c4f5aa48b1cee80b3a98c",
      "ac31481e70a64d85a1d0bc92ac55a2a6",
      "09bcfc952b4b41feb0c3ecd5f52ea2a6"
     ]
    },
    "id": "WoKkCWUhM0LE",
    "outputId": "f072e5fb-3c3f-4edc-b2f6-68c52a742b98"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b1dee852c5b4748842c88af3c6ca0db"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85e28eea8b874d44ae4651ebae56d7b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω\n",
      "Train: 455\n",
      "Validation: 51\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": \"data/train.json\",\n",
    "        \"validation\": \"data/validation.json\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω\")\n",
    "print(f\"Train: {len(dataset['train'])}\")\n",
    "print(f\"Validation: {len(dataset['validation'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "1949ae18854b4fc1a4f8ecb12ee8c0d3",
      "1b887f28bea348ae87280e54b9497b82",
      "9bb33ffb12574600b06dc4f413cf4445",
      "d914470fe8d94af08cfaf83dc139af62",
      "2bb8a8dfb18b4869aa65e00ad953d0a9",
      "86979cde66684bbaa205cecfa301fcdf",
      "ab751d3886624c34baa8101cbc865108",
      "761c56a0f7fc463c88ad2bec13a9aba6",
      "e87d751382a84717b25572c05321dab9",
      "1377755872d44ceda12f405457881e73",
      "f50dab3733ab446b958f94246fe5d549",
      "acdd49370ba94c389423034bff9cf85b",
      "547b46b78a2f4d17b480d352c965859b",
      "91a36014bb5d43f0970090a4d965587b",
      "3082edbb4f4a4dc794aea4cee2a89a6a",
      "c4102872867c4a6ab93a43632e964335",
      "90d9f36d7cee433d92a2df91183be435",
      "952ba5d58dbf4ef99d9465c17da50cbc",
      "001459bbdbd7466e95b35a856fe5e9d7",
      "7c9117450027495e97ad1972944b49e7",
      "d2b0fc6a71924cae8ca0b2049764018d",
      "8fd41a5f4e2f438fb7dc1a9d7ce36f39"
     ]
    },
    "id": "ETZfDU-lM0LE",
    "outputId": "d46871c7-2a94-4c93-a47f-fce81a7fadbb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/455 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1949ae18854b4fc1a4f8ecb12ee8c0d3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/51 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acdd49370ba94c389423034bff9cf85b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n"
     ]
    }
   ],
   "source": [
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "def tokenize_function(examples):\n",
    "\n",
    "\n",
    "    full_texts = []\n",
    "\n",
    "    for instruction, output in zip(examples['instruction'], examples['output']):\n",
    "        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å—ë –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç\n",
    "        full_text = f\"[INST] {instruction} [/INST] {output}</s>\"\n",
    "        full_texts.append(full_text)\n",
    "\n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Ü–µ–ª–∏–∫–æ–º\n",
    "    model_inputs = tokenizer(\n",
    "        full_texts,\n",
    "        max_length=2048,\n",
    "        padding=False,\n",
    "        truncation=True,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "\n",
    "\n",
    "    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "print(\"–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞...\")\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "print(\"–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryHulwg7M0LE",
    "outputId": "f0ee8a45-e9ff-480b-d711-93674b0c9846"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training arguments –≥–æ—Ç–æ–≤—ã\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_grad_norm=0.3,\n",
    "    bf16=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "    eval_strategy=\"steps\",  # –ò–ó–ú–ï–ù–ò–õ–ò: evaluation_strategy ‚Üí eval_strategy\n",
    "    eval_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    group_by_length=True,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "print(\"Training arguments –≥–æ—Ç–æ–≤—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8fMpNFNM0LG",
    "outputId": "3b941cba-fb8c-44fb-af74-9d3d48c29c9e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trainer –≥–æ—Ç–æ–≤ –∫ –æ–±—É—á–µ–Ω–∏—é\n"
     ]
    }
   ],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Trainer –≥–æ—Ç–æ–≤ –∫ –æ–±—É—á–µ–Ω–∏—é\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "nkfapKLHM0LG",
    "outputId": "c712796a-9b09-4321-cb24-4766f9436f56"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "–ù–ê–ß–ò–ù–ê–ï–ú –û–ë–£–ß–ï–ù–ò–ï\n",
      "============================================================\n",
      "–≠–ø–æ—Ö: 3\n",
      "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch size: 16\n",
      "GPU –ø–∞–º—è—Ç—å: 5.33 GB\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 1:30:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# –û–ë–£–ß–ï–ù–ò–ï\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"–ù–ê–ß–ò–ù–ê–ï–ú –û–ë–£–ß–ï–ù–ò–ï\")\n",
    "print(\"=\"*60)\n",
    "print(f\"–≠–ø–æ—Ö: {training_args.num_train_epochs}\")\n",
    "print(f\"–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"GPU –ø–∞–º—è—Ç—å: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º –±—É—á–µ–Ω–∏–µ\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YN1k94npM0LG",
    "outputId": "0be52c81-dec3-43f7-bcbe-8e7c9ed157b1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ outputs/financial-mistral-qlora/final_model\n"
     ]
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "final_model_path = f\"{OUTPUT_DIR}/final_model\"\n",
    "trainer.model.save_pretrained(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "\n",
    "print(f\"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WIhWPGWM0LG"
   },
   "source": [
    "#–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–ü—Ä–æ–≤–µ—Ä–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "–ü–µ—Ä–µ–¥ —ç—Ç–∏–º –ª—É—á—à–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ä–µ–¥—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"
   ],
   "metadata": {
    "id": "Qya7DlKCxP95"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "OUTPUT_DIR = \"outputs/financial-mistral-qlora\"\n",
    "final_model_path = f\"{OUTPUT_DIR}/final_model\""
   ],
   "metadata": {
    "id": "TwrXRvUawAN8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309,
     "referenced_widgets": [
      "12428314568d481bb2c27cf5e2fa5c8a",
      "3dd14905cf4c472d8cd3ae388fcde115",
      "ff03d05a0a4a463296dbacd5612f3313",
      "e495857523e54461986f6120b1f66ab1",
      "9d487ed443404b44a036794118f536f6",
      "2ce55467e79a4c86b15370ac610e4014",
      "b1e2719657e84ac0afb75efd7c3817b1",
      "8ad5db725bd54c44ab96931ce743cb15",
      "4183018d75384137aecd42586c6cc6ef",
      "f536a93990d445ba9db75c0c19d22d2b",
      "e1497f2a08e541f586a0ce2d34d873d6"
     ]
    },
    "id": "8sY4NUiHM0LG",
    "outputId": "cbc02ddd-7ca8-480c-adfa-4b3d6d3f5d83"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12428314568d481bb2c27cf5e2fa5c8a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –Ω–∞ GPU!\n",
      "–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda:0\n",
      "–ü–∞–º—è—Ç—å: 4.81 GB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "\n",
    "# –û—á–∏—Å—Ç–∫–∞\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞...\")\n",
    "\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-v0.1\"\n",
    "final_model_path = \"outputs/financial-mistral-qlora/final_model\"\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0},\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "\n",
    "inference_model = PeftModel.from_pretrained(\n",
    "    base_model,\n",
    "    final_model_path,\n",
    "    device_map={\"\": 0},\n",
    ")\n",
    "\n",
    "\n",
    "inference_model = inference_model.to(\"cuda\")\n",
    "\n",
    "\n",
    "inference_model.eval()\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "print(f\"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –Ω–∞ GPU!\")\n",
    "print(f\"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {next(inference_model.parameters()).device}\")\n",
    "print(f\"–ü–∞–º—è—Ç—å: {torch.cuda.memory_allocated()/1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uR7Y_UPWM0LG",
    "outputId": "efd70e19-0f0e-46a3-cc6f-d6d0a627816a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–æ—Ç–æ–≤–∞\n"
     ]
    }
   ],
   "source": [
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "\n",
    "def generate_response(instruction, max_new_tokens=512):\n",
    "\n",
    "\n",
    "    prompt = f\"[INST] {instruction} [/INST]\"\n",
    "\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"].to(\"cuda\")\n",
    "    attention_mask = inputs[\"attention_mask\"].to(\"cuda\")\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = inference_model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "    if \"[/INST]\" in response:\n",
    "        response = response.split(\"[/INST]\")[-1].strip()\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "print(\"–§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–æ—Ç–æ–≤–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤:\")\n",
    "print(f\"–ú–æ–¥–µ–ª—å –Ω–∞: {inference_model.device}\")\n",
    "print(f\"CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}\")\n",
    "\n",
    "\n",
    "if str(inference_model.device) == \"cpu\":\n",
    "\n",
    "    inference_model = inference_model.to(\"cuda\")\n",
    "    print(\"–ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –Ω–∞ GPU\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7YZnAItu-wC",
    "outputId": "5984292f-6e48-49ca-8412-8175f4c4f714"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤:\n",
      "–ú–æ–¥–µ–ª—å –Ω–∞: cuda:0\n",
      "CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: True\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thHGZlW5M0LH",
    "outputId": "3bc7c28c-e313-4307-e0a1-f942de3f8ee1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "================================================================================\n",
      "–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò\n",
      "================================================================================\n",
      "\n",
      "\n",
      "[–ü—Ä–∏–º–µ—Ä 1/3]\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "–í–æ–ø—Ä–æ—Å: –†–∞—Å—Å—á–∏—Ç–∞–π ROE –µ—Å–ª–∏ –ø—Ä–∏–±—ã–ª—å 150 –º–ª–Ω —Ä—É–±, –∫–∞–ø–∏—Ç–∞–ª 600 –º–ª–Ω —Ä—É–±\n",
      "\n",
      "–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n",
      "ROE = (–ß–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å / –°–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª) √ó 100% = (150 / 600) √ó 100% = 25.0%\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "[–ü—Ä–∏–º–µ—Ä 2/3]\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "–í–æ–ø—Ä–æ—Å: –¢–µ–∫—É—â–∏–µ –∞–∫—Ç–∏–≤—ã 500 –º–ª–Ω, –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ 300 –º–ª–Ω. –û—Ü–µ–Ω–∏ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å.\n",
      "\n",
      "–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n",
      "–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ç–µ–∫—É—â–µ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ = 500/300 = 1.67. –ù–æ—Ä–º–∞–ª—å–Ω–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –ø–æ–∫—Ä—ã—Ç–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤.\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "[–ü—Ä–∏–º–µ—Ä 3/3]\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "–í–æ–ø—Ä–æ—Å: –ö–æ–º–ø–∞–Ω–∏—è –∏–º–µ–µ—Ç –≤—ã—Ä—É—á–∫—É 1000 –º–ª–Ω, EBITDA 250 –º–ª–Ω. –†–∞—Å—Å—á–∏—Ç–∞–π EBITDA –º–∞—Ä–∂—É.\n",
      "\n",
      "–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n",
      "EBITDA –º–∞—Ä–∂–∞ = (EBITDA / –í—ã—Ä—É—á–∫–∞) √ó 100% = (250 / 1000) √ó 100% = 25.0%\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    }
   ],
   "source": [
    "# –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã\n",
    "test_examples = [\n",
    "    \"–†–∞—Å—Å—á–∏—Ç–∞–π ROE –µ—Å–ª–∏ –ø—Ä–∏–±—ã–ª—å 150 –º–ª–Ω —Ä—É–±, –∫–∞–ø–∏—Ç–∞–ª 600 –º–ª–Ω —Ä—É–±\",\n",
    "    \"–¢–µ–∫—É—â–∏–µ –∞–∫—Ç–∏–≤—ã 500 –º–ª–Ω, –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ 300 –º–ª–Ω. –û—Ü–µ–Ω–∏ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å.\",\n",
    "    \"–ö–æ–º–ø–∞–Ω–∏—è –∏–º–µ–µ—Ç –≤—ã—Ä—É—á–∫—É 1000 –º–ª–Ω, EBITDA 250 –º–ª–Ω. –†–∞—Å—Å—á–∏—Ç–∞–π EBITDA –º–∞—Ä–∂—É.\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for i, example in enumerate(test_examples, 1):\n",
    "    print(f\"\\n[–ü—Ä–∏–º–µ—Ä {i}/{len(test_examples)}]\")\n",
    "    print(\"‚îÄ\" * 80)\n",
    "    print(f\"–í–æ–ø—Ä–æ—Å: {example}\")\n",
    "    print(f\"\\n–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\")\n",
    "    response = generate_response(example)\n",
    "    print(response)\n",
    "    print(\"\\n\" + \"‚îÄ\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import random"
   ],
   "metadata": {
    "id": "MX7HBqZjw-K7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160,
     "referenced_widgets": [
      "f3236178b0b14112b7c2edbc7ed17ca8",
      "7b4d83fbd8b840e093e76957dbc2b7e1",
      "7d2b633dc6e548d0ad6bba24477a001a",
      "76ba5b4a6d2943fc89ad20fb200d2ea7",
      "216484fcd4e4415b849e13ac49a5067a",
      "ee8435db622a4df3b9cd0328bf1b25ff",
      "942adf2c4d3d496287b8974d3d9b5e29",
      "aa5c9426f4d74eeaaf594fd4d9888e6d",
      "dfe0c9942bed429aba87c8d2e21f59cf",
      "29f3f0d7ba1e43adbe7e2d3e97cbd526",
      "1e09bfa36b7c47959d70181d5ea8e34f"
     ]
    },
    "id": "LZCWnu7ZM0LH",
    "outputId": "194074f5-e15f-4845-b6b1-43e8ca40703e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "–û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ (10 –ø—Ä–∏–º–µ—Ä–æ–≤):\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è:   0%|          | 0/10 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3236178b0b14112b7c2edbc7ed17ca8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
    "with open('data/validation.json', 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "# –ë–µ—Ä—ë–º 10 —Å–ª—É—á–∞–π–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—Ü–µ–Ω–∫–∏\n",
    "sample_val = random.sample(val_data, min(10, len(val_data)))\n",
    "\n",
    "print(\"\\n–û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ (10 –ø—Ä–∏–º–µ—Ä–æ–≤):\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for example in tqdm(sample_val, desc=\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è\"):\n",
    "    pred = generate_response(example['instruction'])\n",
    "    predictions.append(pred)\n",
    "    references.append(example['output'])\n",
    "\n",
    "print(\"\\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QshL0PUnM0LH",
    "outputId": "8cd617ba-1389-47ae-c7f2-bd9b032fe2e5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¶–ï–ù–ö–ò:\n",
      "================================================================================\n",
      "ROUGE-1: 0.8268\n",
      "ROUGE-2: 0.7857\n",
      "ROUGE-L: 0.8268\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "rouge1_scores = []\n",
    "rouge2_scores = []\n",
    "rougeL_scores = []\n",
    "\n",
    "for pred, ref in zip(predictions, references):\n",
    "    scores = scorer.score(ref, pred)\n",
    "    rouge1_scores.append(scores['rouge1'].fmeasure)\n",
    "    rouge2_scores.append(scores['rouge2'].fmeasure)\n",
    "    rougeL_scores.append(scores['rougeL'].fmeasure)\n",
    "\n",
    "print(\"\\n–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¶–ï–ù–ö–ò:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ROUGE-1: {np.mean(rouge1_scores):.4f}\")\n",
    "print(f\"ROUGE-2: {np.mean(rouge2_scores):.4f}\")\n",
    "print(f\"ROUGE-L: {np.mean(rougeL_scores):.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ud2qxWkiM0LH"
   },
   "source": [
    "#–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3vXoI_2M0LH",
    "outputId": "87986e84-7bcd-43b1-9707-82807974718e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "–í–æ–ø—Ä–æ—Å:\n",
      "–û—Ü–µ–Ω–∏ –∫—Ä–µ–¥–∏—Ç–Ω—ã–π —Ä–∏—Å–∫: –ò–ü, —Å—Ç–∞–∂ 2 –≥–æ–¥–∞, –≤—ã—Ä—É—á–∫–∞ 1 –º–ª–Ω/–º–µ—Å, –¥–æ–ª–≥ 30%\n",
      "\n",
      "–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ç–µ–∫—É—â–µ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ = 300/1000 = 0.30. ‚ö†Ô∏è –ù–∏–∑–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å, —Ä–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º —Å –ø–æ–≥–∞—à–µ–Ω–∏–µ–º –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤.\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "your_question = \"–û—Ü–µ–Ω–∏ –∫—Ä–µ–¥–∏—Ç–Ω—ã–π —Ä–∏—Å–∫: –ò–ü, —Å—Ç–∞–∂ 2 –≥–æ–¥–∞, –≤—ã—Ä—É—á–∫–∞ 1 –º–ª–Ω/–º–µ—Å, –¥–æ–ª–≥ 30%\"  # –ò–ó–ú–ï–ù–ò –≠–¢–û\n",
    "\n",
    "print(\"\\n–í–æ–ø—Ä–æ—Å:\")\n",
    "print(your_question)\n",
    "print(\"\\n–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\")\n",
    "print(\"‚îÄ\" * 80)\n",
    "response = generate_response(your_question)\n",
    "print(response)\n",
    "print(\"‚îÄ\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNBEX56DM0LH"
   },
   "source": [
    "#–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHGvokXBM0LH",
    "outputId": "f0117241-0282-42ab-c941-ccefdb319ae1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ outputs/financial-mistral-qlora/results.json\n",
      "\n",
      "================================================================================\n",
      "–§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´\n",
      "================================================================================\n",
      "\n",
      "–ú–æ–¥–µ–ª—å: mistralai/Mistral-7B-v0.1\n",
      "–≠–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è: 3\n",
      "\n",
      "–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:\n",
      "  ROUGE-1: 0.8268\n",
      "  ROUGE-2: 0.7857\n",
      "  ROUGE-L: 0.8268\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "results = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"dataset_size\": len(val_data),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º val_data –≤–º–µ—Å—Ç–æ dataset\n",
    "    \"val_samples\": len(val_data),\n",
    "    \"epochs\": 3,\n",
    "    \"metrics\": {\n",
    "        \"rouge1\": float(np.mean(rouge1_scores)),\n",
    "        \"rouge2\": float(np.mean(rouge2_scores)),\n",
    "        \"rougeL\": float(np.mean(rougeL_scores)),\n",
    "    },\n",
    "    \"sample_predictions\": [\n",
    "        {\n",
    "            \"instruction\": sample_val[i]['instruction'],\n",
    "            \"reference\": sample_val[i]['output'],\n",
    "            \"prediction\": predictions[i]\n",
    "        }\n",
    "        for i in range(min(3, len(predictions)))\n",
    "    ]\n",
    "}\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "OUTPUT_DIR = \"outputs/financial-mistral-qlora\"\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {OUTPUT_DIR}/results.json\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"–§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n–ú–æ–¥–µ–ª—å: {MODEL_NAME}\")\n",
    "print(f\"–≠–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è: 3\")\n",
    "print(f\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:\")\n",
    "print(f\"  ROUGE-1: {results['metrics']['rouge1']:.4f}\")\n",
    "print(f\"  ROUGE-2: {results['metrics']['rouge2']:.4f}\")\n",
    "print(f\"  ROUGE-L: {results['metrics']['rougeL']:.4f}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0

}
